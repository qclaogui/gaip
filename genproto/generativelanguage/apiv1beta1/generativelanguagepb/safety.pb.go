// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v6.30.1
// source: qclaogui/generativelanguage/v1beta1/safety.proto

package generativelanguagepb

import (
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"

	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// The category of a rating.
//
// These categories cover various kinds of harms that developers
// may wish to adjust.
type HarmCategory int32

const (
	// Category is unspecified.
	HarmCategory_HARM_CATEGORY_UNSPECIFIED HarmCategory = 0
	// **PaLM** - Negative or harmful comments targeting identity and/or protected
	// attribute.
	HarmCategory_HARM_CATEGORY_DEROGATORY HarmCategory = 1
	// **PaLM** - Content that is rude, disrespectful, or profane.
	HarmCategory_HARM_CATEGORY_TOXICITY HarmCategory = 2
	// **PaLM** - Describes scenarios depicting violence against an individual or
	// group, or general descriptions of gore.
	HarmCategory_HARM_CATEGORY_VIOLENCE HarmCategory = 3
	// **PaLM** - Contains references to sexual acts or other lewd content.
	HarmCategory_HARM_CATEGORY_SEXUAL HarmCategory = 4
	// **PaLM** - Promotes unchecked medical advice.
	HarmCategory_HARM_CATEGORY_MEDICAL HarmCategory = 5
	// **PaLM** - Dangerous content that promotes, facilitates, or encourages
	// harmful acts.
	HarmCategory_HARM_CATEGORY_DANGEROUS HarmCategory = 6
	// **Gemini** - Harassment content.
	HarmCategory_HARM_CATEGORY_HARASSMENT HarmCategory = 7
	// **Gemini** - Hate speech and content.
	HarmCategory_HARM_CATEGORY_HATE_SPEECH HarmCategory = 8
	// **Gemini** - Sexually explicit content.
	HarmCategory_HARM_CATEGORY_SEXUALLY_EXPLICIT HarmCategory = 9
	// **Gemini** - Dangerous content.
	HarmCategory_HARM_CATEGORY_DANGEROUS_CONTENT HarmCategory = 10
	// **Gemini** - Content that may be used to harm civic integrity.
	HarmCategory_HARM_CATEGORY_CIVIC_INTEGRITY HarmCategory = 11
)

// Enum value maps for HarmCategory.
var (
	HarmCategory_name = map[int32]string{
		0:  "HARM_CATEGORY_UNSPECIFIED",
		1:  "HARM_CATEGORY_DEROGATORY",
		2:  "HARM_CATEGORY_TOXICITY",
		3:  "HARM_CATEGORY_VIOLENCE",
		4:  "HARM_CATEGORY_SEXUAL",
		5:  "HARM_CATEGORY_MEDICAL",
		6:  "HARM_CATEGORY_DANGEROUS",
		7:  "HARM_CATEGORY_HARASSMENT",
		8:  "HARM_CATEGORY_HATE_SPEECH",
		9:  "HARM_CATEGORY_SEXUALLY_EXPLICIT",
		10: "HARM_CATEGORY_DANGEROUS_CONTENT",
		11: "HARM_CATEGORY_CIVIC_INTEGRITY",
	}
	HarmCategory_value = map[string]int32{
		"HARM_CATEGORY_UNSPECIFIED":       0,
		"HARM_CATEGORY_DEROGATORY":        1,
		"HARM_CATEGORY_TOXICITY":          2,
		"HARM_CATEGORY_VIOLENCE":          3,
		"HARM_CATEGORY_SEXUAL":            4,
		"HARM_CATEGORY_MEDICAL":           5,
		"HARM_CATEGORY_DANGEROUS":         6,
		"HARM_CATEGORY_HARASSMENT":        7,
		"HARM_CATEGORY_HATE_SPEECH":       8,
		"HARM_CATEGORY_SEXUALLY_EXPLICIT": 9,
		"HARM_CATEGORY_DANGEROUS_CONTENT": 10,
		"HARM_CATEGORY_CIVIC_INTEGRITY":   11,
	}
)

func (x HarmCategory) Enum() *HarmCategory {
	p := new(HarmCategory)
	*p = x
	return p
}

func (x HarmCategory) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (HarmCategory) Descriptor() protoreflect.EnumDescriptor {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[0].Descriptor()
}

func (HarmCategory) Type() protoreflect.EnumType {
	return &file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[0]
}

func (x HarmCategory) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use HarmCategory.Descriptor instead.
func (HarmCategory) EnumDescriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{0}
}

// A list of reasons why content may have been blocked.
type ContentFilter_BlockedReason int32

const (
	// A blocked reason was not specified.
	ContentFilter_BLOCKED_REASON_UNSPECIFIED ContentFilter_BlockedReason = 0
	// Content was blocked by safety settings.
	ContentFilter_SAFETY ContentFilter_BlockedReason = 1
	// Content was blocked, but the reason is uncategorized.
	ContentFilter_OTHER ContentFilter_BlockedReason = 2
)

// Enum value maps for ContentFilter_BlockedReason.
var (
	ContentFilter_BlockedReason_name = map[int32]string{
		0: "BLOCKED_REASON_UNSPECIFIED",
		1: "SAFETY",
		2: "OTHER",
	}
	ContentFilter_BlockedReason_value = map[string]int32{
		"BLOCKED_REASON_UNSPECIFIED": 0,
		"SAFETY":                     1,
		"OTHER":                      2,
	}
)

func (x ContentFilter_BlockedReason) Enum() *ContentFilter_BlockedReason {
	p := new(ContentFilter_BlockedReason)
	*p = x
	return p
}

func (x ContentFilter_BlockedReason) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ContentFilter_BlockedReason) Descriptor() protoreflect.EnumDescriptor {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[1].Descriptor()
}

func (ContentFilter_BlockedReason) Type() protoreflect.EnumType {
	return &file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[1]
}

func (x ContentFilter_BlockedReason) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ContentFilter_BlockedReason.Descriptor instead.
func (ContentFilter_BlockedReason) EnumDescriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{0, 0}
}

// The probability that a piece of content is harmful.
//
// The classification system gives the probability of the content being
// unsafe. This does not indicate the severity of harm for a piece of content.
type SafetyRating_HarmProbability int32

const (
	// Probability is unspecified.
	SafetyRating_HARM_PROBABILITY_UNSPECIFIED SafetyRating_HarmProbability = 0
	// Content has a negligible chance of being unsafe.
	SafetyRating_NEGLIGIBLE SafetyRating_HarmProbability = 1
	// Content has a low chance of being unsafe.
	SafetyRating_LOW SafetyRating_HarmProbability = 2
	// Content has a medium chance of being unsafe.
	SafetyRating_MEDIUM SafetyRating_HarmProbability = 3
	// Content has a high chance of being unsafe.
	SafetyRating_HIGH SafetyRating_HarmProbability = 4
)

// Enum value maps for SafetyRating_HarmProbability.
var (
	SafetyRating_HarmProbability_name = map[int32]string{
		0: "HARM_PROBABILITY_UNSPECIFIED",
		1: "NEGLIGIBLE",
		2: "LOW",
		3: "MEDIUM",
		4: "HIGH",
	}
	SafetyRating_HarmProbability_value = map[string]int32{
		"HARM_PROBABILITY_UNSPECIFIED": 0,
		"NEGLIGIBLE":                   1,
		"LOW":                          2,
		"MEDIUM":                       3,
		"HIGH":                         4,
	}
)

func (x SafetyRating_HarmProbability) Enum() *SafetyRating_HarmProbability {
	p := new(SafetyRating_HarmProbability)
	*p = x
	return p
}

func (x SafetyRating_HarmProbability) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SafetyRating_HarmProbability) Descriptor() protoreflect.EnumDescriptor {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[2].Descriptor()
}

func (SafetyRating_HarmProbability) Type() protoreflect.EnumType {
	return &file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[2]
}

func (x SafetyRating_HarmProbability) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SafetyRating_HarmProbability.Descriptor instead.
func (SafetyRating_HarmProbability) EnumDescriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{2, 0}
}

// Block at and beyond a specified harm probability.
type SafetySetting_HarmBlockThreshold int32

const (
	// Threshold is unspecified.
	SafetySetting_HARM_BLOCK_THRESHOLD_UNSPECIFIED SafetySetting_HarmBlockThreshold = 0
	// Content with NEGLIGIBLE will be allowed.
	SafetySetting_BLOCK_LOW_AND_ABOVE SafetySetting_HarmBlockThreshold = 1
	// Content with NEGLIGIBLE and LOW will be allowed.
	SafetySetting_BLOCK_MEDIUM_AND_ABOVE SafetySetting_HarmBlockThreshold = 2
	// Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
	SafetySetting_BLOCK_ONLY_HIGH SafetySetting_HarmBlockThreshold = 3
	// All content will be allowed.
	SafetySetting_BLOCK_NONE SafetySetting_HarmBlockThreshold = 4
	// Turn off the safety filter.
	SafetySetting_OFF SafetySetting_HarmBlockThreshold = 5
)

// Enum value maps for SafetySetting_HarmBlockThreshold.
var (
	SafetySetting_HarmBlockThreshold_name = map[int32]string{
		0: "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
		1: "BLOCK_LOW_AND_ABOVE",
		2: "BLOCK_MEDIUM_AND_ABOVE",
		3: "BLOCK_ONLY_HIGH",
		4: "BLOCK_NONE",
		5: "OFF",
	}
	SafetySetting_HarmBlockThreshold_value = map[string]int32{
		"HARM_BLOCK_THRESHOLD_UNSPECIFIED": 0,
		"BLOCK_LOW_AND_ABOVE":              1,
		"BLOCK_MEDIUM_AND_ABOVE":           2,
		"BLOCK_ONLY_HIGH":                  3,
		"BLOCK_NONE":                       4,
		"OFF":                              5,
	}
)

func (x SafetySetting_HarmBlockThreshold) Enum() *SafetySetting_HarmBlockThreshold {
	p := new(SafetySetting_HarmBlockThreshold)
	*p = x
	return p
}

func (x SafetySetting_HarmBlockThreshold) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SafetySetting_HarmBlockThreshold) Descriptor() protoreflect.EnumDescriptor {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[3].Descriptor()
}

func (SafetySetting_HarmBlockThreshold) Type() protoreflect.EnumType {
	return &file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes[3]
}

func (x SafetySetting_HarmBlockThreshold) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SafetySetting_HarmBlockThreshold.Descriptor instead.
func (SafetySetting_HarmBlockThreshold) EnumDescriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{3, 0}
}

// Content filtering metadata associated with processing a single request.
//
// ContentFilter contains a reason and an optional supporting string. The reason
// may be unspecified.
type ContentFilter struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The reason content was blocked during request processing.
	Reason ContentFilter_BlockedReason `protobuf:"varint,1,opt,name=reason,proto3,enum=qclaogui.generativelanguage.v1beta1.ContentFilter_BlockedReason" json:"reason,omitempty"`
	// A string that describes the filtering behavior in more detail.
	Message       *string `protobuf:"bytes,2,opt,name=message,proto3,oneof" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ContentFilter) Reset() {
	*x = ContentFilter{}
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ContentFilter) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ContentFilter) ProtoMessage() {}

func (x *ContentFilter) ProtoReflect() protoreflect.Message {
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ContentFilter.ProtoReflect.Descriptor instead.
func (*ContentFilter) Descriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{0}
}

func (x *ContentFilter) GetReason() ContentFilter_BlockedReason {
	if x != nil {
		return x.Reason
	}
	return ContentFilter_BLOCKED_REASON_UNSPECIFIED
}

func (x *ContentFilter) GetMessage() string {
	if x != nil && x.Message != nil {
		return *x.Message
	}
	return ""
}

// Safety feedback for an entire request.
//
// This field is populated if content in the input and/or response is blocked
// due to safety settings. SafetyFeedback may not exist for every HarmCategory.
// Each SafetyFeedback will return the safety settings used by the request as
// well as the lowest HarmProbability that should be allowed in order to return
// a result.
type SafetyFeedback struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Safety rating evaluated from content.
	Rating *SafetyRating `protobuf:"bytes,1,opt,name=rating,proto3" json:"rating,omitempty"`
	// Safety settings applied to the request.
	Setting       *SafetySetting `protobuf:"bytes,2,opt,name=setting,proto3" json:"setting,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SafetyFeedback) Reset() {
	*x = SafetyFeedback{}
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SafetyFeedback) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SafetyFeedback) ProtoMessage() {}

func (x *SafetyFeedback) ProtoReflect() protoreflect.Message {
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SafetyFeedback.ProtoReflect.Descriptor instead.
func (*SafetyFeedback) Descriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{1}
}

func (x *SafetyFeedback) GetRating() *SafetyRating {
	if x != nil {
		return x.Rating
	}
	return nil
}

func (x *SafetyFeedback) GetSetting() *SafetySetting {
	if x != nil {
		return x.Setting
	}
	return nil
}

// Safety rating for a piece of content.
//
// The safety rating contains the category of harm and the
// harm probability level in that category for a piece of content.
// Content is classified for safety across a number of
// harm categories and the probability of the harm classification is included
// here.
type SafetyRating struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The category for this rating.
	Category HarmCategory `protobuf:"varint,3,opt,name=category,proto3,enum=qclaogui.generativelanguage.v1beta1.HarmCategory" json:"category,omitempty"`
	// Required. The probability of harm for this content.
	Probability SafetyRating_HarmProbability `protobuf:"varint,4,opt,name=probability,proto3,enum=qclaogui.generativelanguage.v1beta1.SafetyRating_HarmProbability" json:"probability,omitempty"`
	// Was this content blocked because of this rating?
	Blocked       bool `protobuf:"varint,5,opt,name=blocked,proto3" json:"blocked,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SafetyRating) Reset() {
	*x = SafetyRating{}
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SafetyRating) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SafetyRating) ProtoMessage() {}

func (x *SafetyRating) ProtoReflect() protoreflect.Message {
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SafetyRating.ProtoReflect.Descriptor instead.
func (*SafetyRating) Descriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{2}
}

func (x *SafetyRating) GetCategory() HarmCategory {
	if x != nil {
		return x.Category
	}
	return HarmCategory_HARM_CATEGORY_UNSPECIFIED
}

func (x *SafetyRating) GetProbability() SafetyRating_HarmProbability {
	if x != nil {
		return x.Probability
	}
	return SafetyRating_HARM_PROBABILITY_UNSPECIFIED
}

func (x *SafetyRating) GetBlocked() bool {
	if x != nil {
		return x.Blocked
	}
	return false
}

// Safety setting, affecting the safety-blocking behavior.
//
// Passing a safety setting for a category changes the allowed probability that
// content is blocked.
type SafetySetting struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The category for this setting.
	Category HarmCategory `protobuf:"varint,3,opt,name=category,proto3,enum=qclaogui.generativelanguage.v1beta1.HarmCategory" json:"category,omitempty"`
	// Required. Controls the probability threshold at which harm is blocked.
	Threshold     SafetySetting_HarmBlockThreshold `protobuf:"varint,4,opt,name=threshold,proto3,enum=qclaogui.generativelanguage.v1beta1.SafetySetting_HarmBlockThreshold" json:"threshold,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SafetySetting) Reset() {
	*x = SafetySetting{}
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SafetySetting) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SafetySetting) ProtoMessage() {}

func (x *SafetySetting) ProtoReflect() protoreflect.Message {
	mi := &file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SafetySetting.ProtoReflect.Descriptor instead.
func (*SafetySetting) Descriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP(), []int{3}
}

func (x *SafetySetting) GetCategory() HarmCategory {
	if x != nil {
		return x.Category
	}
	return HarmCategory_HARM_CATEGORY_UNSPECIFIED
}

func (x *SafetySetting) GetThreshold() SafetySetting_HarmBlockThreshold {
	if x != nil {
		return x.Threshold
	}
	return SafetySetting_HARM_BLOCK_THRESHOLD_UNSPECIFIED
}

var File_qclaogui_generativelanguage_v1beta1_safety_proto protoreflect.FileDescriptor

const file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDesc = "" +
	"\n" +
	"0qclaogui/generativelanguage/v1beta1/safety.proto\x12#qclaogui.generativelanguage.v1beta1\x1a\x1fgoogle/api/field_behavior.proto\"\xdc\x01\n" +
	"\rContentFilter\x12X\n" +
	"\x06reason\x18\x01 \x01(\x0e2@.qclaogui.generativelanguage.v1beta1.ContentFilter.BlockedReasonR\x06reason\x12\x1d\n" +
	"\amessage\x18\x02 \x01(\tH\x00R\amessage\x88\x01\x01\"F\n" +
	"\rBlockedReason\x12\x1e\n" +
	"\x1aBLOCKED_REASON_UNSPECIFIED\x10\x00\x12\n" +
	"\n" +
	"\x06SAFETY\x10\x01\x12\t\n" +
	"\x05OTHER\x10\x02B\n" +
	"\n" +
	"\b_message\"\xa9\x01\n" +
	"\x0eSafetyFeedback\x12I\n" +
	"\x06rating\x18\x01 \x01(\v21.qclaogui.generativelanguage.v1beta1.SafetyRatingR\x06rating\x12L\n" +
	"\asetting\x18\x02 \x01(\v22.qclaogui.generativelanguage.v1beta1.SafetySettingR\asetting\"\xcc\x02\n" +
	"\fSafetyRating\x12S\n" +
	"\bcategory\x18\x03 \x01(\x0e21.qclaogui.generativelanguage.v1beta1.HarmCategoryB\x04\xe2A\x01\x02R\bcategory\x12i\n" +
	"\vprobability\x18\x04 \x01(\x0e2A.qclaogui.generativelanguage.v1beta1.SafetyRating.HarmProbabilityB\x04\xe2A\x01\x02R\vprobability\x12\x18\n" +
	"\ablocked\x18\x05 \x01(\bR\ablocked\"b\n" +
	"\x0fHarmProbability\x12 \n" +
	"\x1cHARM_PROBABILITY_UNSPECIFIED\x10\x00\x12\x0e\n" +
	"\n" +
	"NEGLIGIBLE\x10\x01\x12\a\n" +
	"\x03LOW\x10\x02\x12\n" +
	"\n" +
	"\x06MEDIUM\x10\x03\x12\b\n" +
	"\x04HIGH\x10\x04\"\xef\x02\n" +
	"\rSafetySetting\x12S\n" +
	"\bcategory\x18\x03 \x01(\x0e21.qclaogui.generativelanguage.v1beta1.HarmCategoryB\x04\xe2A\x01\x02R\bcategory\x12i\n" +
	"\tthreshold\x18\x04 \x01(\x0e2E.qclaogui.generativelanguage.v1beta1.SafetySetting.HarmBlockThresholdB\x04\xe2A\x01\x02R\tthreshold\"\x9d\x01\n" +
	"\x12HarmBlockThreshold\x12$\n" +
	" HARM_BLOCK_THRESHOLD_UNSPECIFIED\x10\x00\x12\x17\n" +
	"\x13BLOCK_LOW_AND_ABOVE\x10\x01\x12\x1a\n" +
	"\x16BLOCK_MEDIUM_AND_ABOVE\x10\x02\x12\x13\n" +
	"\x0fBLOCK_ONLY_HIGH\x10\x03\x12\x0e\n" +
	"\n" +
	"BLOCK_NONE\x10\x04\x12\a\n" +
	"\x03OFF\x10\x05*\xff\x02\n" +
	"\fHarmCategory\x12\x1d\n" +
	"\x19HARM_CATEGORY_UNSPECIFIED\x10\x00\x12\x1c\n" +
	"\x18HARM_CATEGORY_DEROGATORY\x10\x01\x12\x1a\n" +
	"\x16HARM_CATEGORY_TOXICITY\x10\x02\x12\x1a\n" +
	"\x16HARM_CATEGORY_VIOLENCE\x10\x03\x12\x18\n" +
	"\x14HARM_CATEGORY_SEXUAL\x10\x04\x12\x19\n" +
	"\x15HARM_CATEGORY_MEDICAL\x10\x05\x12\x1b\n" +
	"\x17HARM_CATEGORY_DANGEROUS\x10\x06\x12\x1c\n" +
	"\x18HARM_CATEGORY_HARASSMENT\x10\a\x12\x1d\n" +
	"\x19HARM_CATEGORY_HATE_SPEECH\x10\b\x12#\n" +
	"\x1fHARM_CATEGORY_SEXUALLY_EXPLICIT\x10\t\x12#\n" +
	"\x1fHARM_CATEGORY_DANGEROUS_CONTENT\x10\n" +
	"\x12!\n" +
	"\x1dHARM_CATEGORY_CIVIC_INTEGRITY\x10\vBVZTgithub.com/qclaogui/gaip/genproto/generativelanguage/apiv1beta1/generativelanguagepbb\x06proto3"

var (
	file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescOnce sync.Once
	file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescData []byte
)

func file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescGZIP() []byte {
	file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescOnce.Do(func() {
		file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDesc), len(file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDesc)))
	})
	return file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDescData
}

var (
	file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes = make([]protoimpl.EnumInfo, 4)
	file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes  = make([]protoimpl.MessageInfo, 4)
	file_qclaogui_generativelanguage_v1beta1_safety_proto_goTypes   = []any{
		(HarmCategory)(0),                     // 0: qclaogui.generativelanguage.v1beta1.HarmCategory
		(ContentFilter_BlockedReason)(0),      // 1: qclaogui.generativelanguage.v1beta1.ContentFilter.BlockedReason
		(SafetyRating_HarmProbability)(0),     // 2: qclaogui.generativelanguage.v1beta1.SafetyRating.HarmProbability
		(SafetySetting_HarmBlockThreshold)(0), // 3: qclaogui.generativelanguage.v1beta1.SafetySetting.HarmBlockThreshold
		(*ContentFilter)(nil),                 // 4: qclaogui.generativelanguage.v1beta1.ContentFilter
		(*SafetyFeedback)(nil),                // 5: qclaogui.generativelanguage.v1beta1.SafetyFeedback
		(*SafetyRating)(nil),                  // 6: qclaogui.generativelanguage.v1beta1.SafetyRating
		(*SafetySetting)(nil),                 // 7: qclaogui.generativelanguage.v1beta1.SafetySetting
	}
)

var file_qclaogui_generativelanguage_v1beta1_safety_proto_depIdxs = []int32{
	1, // 0: qclaogui.generativelanguage.v1beta1.ContentFilter.reason:type_name -> qclaogui.generativelanguage.v1beta1.ContentFilter.BlockedReason
	6, // 1: qclaogui.generativelanguage.v1beta1.SafetyFeedback.rating:type_name -> qclaogui.generativelanguage.v1beta1.SafetyRating
	7, // 2: qclaogui.generativelanguage.v1beta1.SafetyFeedback.setting:type_name -> qclaogui.generativelanguage.v1beta1.SafetySetting
	0, // 3: qclaogui.generativelanguage.v1beta1.SafetyRating.category:type_name -> qclaogui.generativelanguage.v1beta1.HarmCategory
	2, // 4: qclaogui.generativelanguage.v1beta1.SafetyRating.probability:type_name -> qclaogui.generativelanguage.v1beta1.SafetyRating.HarmProbability
	0, // 5: qclaogui.generativelanguage.v1beta1.SafetySetting.category:type_name -> qclaogui.generativelanguage.v1beta1.HarmCategory
	3, // 6: qclaogui.generativelanguage.v1beta1.SafetySetting.threshold:type_name -> qclaogui.generativelanguage.v1beta1.SafetySetting.HarmBlockThreshold
	7, // [7:7] is the sub-list for method output_type
	7, // [7:7] is the sub-list for method input_type
	7, // [7:7] is the sub-list for extension type_name
	7, // [7:7] is the sub-list for extension extendee
	0, // [0:7] is the sub-list for field type_name
}

func init() { file_qclaogui_generativelanguage_v1beta1_safety_proto_init() }
func file_qclaogui_generativelanguage_v1beta1_safety_proto_init() {
	if File_qclaogui_generativelanguage_v1beta1_safety_proto != nil {
		return
	}
	file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes[0].OneofWrappers = []any{}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDesc), len(file_qclaogui_generativelanguage_v1beta1_safety_proto_rawDesc)),
			NumEnums:      4,
			NumMessages:   4,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_qclaogui_generativelanguage_v1beta1_safety_proto_goTypes,
		DependencyIndexes: file_qclaogui_generativelanguage_v1beta1_safety_proto_depIdxs,
		EnumInfos:         file_qclaogui_generativelanguage_v1beta1_safety_proto_enumTypes,
		MessageInfos:      file_qclaogui_generativelanguage_v1beta1_safety_proto_msgTypes,
	}.Build()
	File_qclaogui_generativelanguage_v1beta1_safety_proto = out.File
	file_qclaogui_generativelanguage_v1beta1_safety_proto_goTypes = nil
	file_qclaogui_generativelanguage_v1beta1_safety_proto_depIdxs = nil
}
