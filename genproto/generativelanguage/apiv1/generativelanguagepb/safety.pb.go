// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v6.30.1
// source: qclaogui/generativelanguage/v1/safety.proto

package generativelanguagepb

import (
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"

	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// The category of a rating.
//
// These categories cover various kinds of harms that developers
// may wish to adjust.
type HarmCategory int32

const (
	// Category is unspecified.
	HarmCategory_HARM_CATEGORY_UNSPECIFIED HarmCategory = 0
	// **PaLM** - Negative or harmful comments targeting identity and/or protected
	// attribute.
	HarmCategory_HARM_CATEGORY_DEROGATORY HarmCategory = 1
	// **PaLM** - Content that is rude, disrespectful, or profane.
	HarmCategory_HARM_CATEGORY_TOXICITY HarmCategory = 2
	// **PaLM** - Describes scenarios depicting violence against an individual or
	// group, or general descriptions of gore.
	HarmCategory_HARM_CATEGORY_VIOLENCE HarmCategory = 3
	// **PaLM** - Contains references to sexual acts or other lewd content.
	HarmCategory_HARM_CATEGORY_SEXUAL HarmCategory = 4
	// **PaLM** - Promotes unchecked medical advice.
	HarmCategory_HARM_CATEGORY_MEDICAL HarmCategory = 5
	// **PaLM** - Dangerous content that promotes, facilitates, or encourages
	// harmful acts.
	HarmCategory_HARM_CATEGORY_DANGEROUS HarmCategory = 6
	// **Gemini** - Harassment content.
	HarmCategory_HARM_CATEGORY_HARASSMENT HarmCategory = 7
	// **Gemini** - Hate speech and content.
	HarmCategory_HARM_CATEGORY_HATE_SPEECH HarmCategory = 8
	// **Gemini** - Sexually explicit content.
	HarmCategory_HARM_CATEGORY_SEXUALLY_EXPLICIT HarmCategory = 9
	// **Gemini** - Dangerous content.
	HarmCategory_HARM_CATEGORY_DANGEROUS_CONTENT HarmCategory = 10
	// **Gemini** - Content that may be used to harm civic integrity.
	HarmCategory_HARM_CATEGORY_CIVIC_INTEGRITY HarmCategory = 11
)

// Enum value maps for HarmCategory.
var (
	HarmCategory_name = map[int32]string{
		0:  "HARM_CATEGORY_UNSPECIFIED",
		1:  "HARM_CATEGORY_DEROGATORY",
		2:  "HARM_CATEGORY_TOXICITY",
		3:  "HARM_CATEGORY_VIOLENCE",
		4:  "HARM_CATEGORY_SEXUAL",
		5:  "HARM_CATEGORY_MEDICAL",
		6:  "HARM_CATEGORY_DANGEROUS",
		7:  "HARM_CATEGORY_HARASSMENT",
		8:  "HARM_CATEGORY_HATE_SPEECH",
		9:  "HARM_CATEGORY_SEXUALLY_EXPLICIT",
		10: "HARM_CATEGORY_DANGEROUS_CONTENT",
		11: "HARM_CATEGORY_CIVIC_INTEGRITY",
	}
	HarmCategory_value = map[string]int32{
		"HARM_CATEGORY_UNSPECIFIED":       0,
		"HARM_CATEGORY_DEROGATORY":        1,
		"HARM_CATEGORY_TOXICITY":          2,
		"HARM_CATEGORY_VIOLENCE":          3,
		"HARM_CATEGORY_SEXUAL":            4,
		"HARM_CATEGORY_MEDICAL":           5,
		"HARM_CATEGORY_DANGEROUS":         6,
		"HARM_CATEGORY_HARASSMENT":        7,
		"HARM_CATEGORY_HATE_SPEECH":       8,
		"HARM_CATEGORY_SEXUALLY_EXPLICIT": 9,
		"HARM_CATEGORY_DANGEROUS_CONTENT": 10,
		"HARM_CATEGORY_CIVIC_INTEGRITY":   11,
	}
)

func (x HarmCategory) Enum() *HarmCategory {
	p := new(HarmCategory)
	*p = x
	return p
}

func (x HarmCategory) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (HarmCategory) Descriptor() protoreflect.EnumDescriptor {
	return file_qclaogui_generativelanguage_v1_safety_proto_enumTypes[0].Descriptor()
}

func (HarmCategory) Type() protoreflect.EnumType {
	return &file_qclaogui_generativelanguage_v1_safety_proto_enumTypes[0]
}

func (x HarmCategory) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use HarmCategory.Descriptor instead.
func (HarmCategory) EnumDescriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1_safety_proto_rawDescGZIP(), []int{0}
}

// The probability that a piece of content is harmful.
//
// The classification system gives the probability of the content being
// unsafe. This does not indicate the severity of harm for a piece of content.
type SafetyRating_HarmProbability int32

const (
	// Probability is unspecified.
	SafetyRating_HARM_PROBABILITY_UNSPECIFIED SafetyRating_HarmProbability = 0
	// Content has a negligible chance of being unsafe.
	SafetyRating_NEGLIGIBLE SafetyRating_HarmProbability = 1
	// Content has a low chance of being unsafe.
	SafetyRating_LOW SafetyRating_HarmProbability = 2
	// Content has a medium chance of being unsafe.
	SafetyRating_MEDIUM SafetyRating_HarmProbability = 3
	// Content has a high chance of being unsafe.
	SafetyRating_HIGH SafetyRating_HarmProbability = 4
)

// Enum value maps for SafetyRating_HarmProbability.
var (
	SafetyRating_HarmProbability_name = map[int32]string{
		0: "HARM_PROBABILITY_UNSPECIFIED",
		1: "NEGLIGIBLE",
		2: "LOW",
		3: "MEDIUM",
		4: "HIGH",
	}
	SafetyRating_HarmProbability_value = map[string]int32{
		"HARM_PROBABILITY_UNSPECIFIED": 0,
		"NEGLIGIBLE":                   1,
		"LOW":                          2,
		"MEDIUM":                       3,
		"HIGH":                         4,
	}
)

func (x SafetyRating_HarmProbability) Enum() *SafetyRating_HarmProbability {
	p := new(SafetyRating_HarmProbability)
	*p = x
	return p
}

func (x SafetyRating_HarmProbability) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SafetyRating_HarmProbability) Descriptor() protoreflect.EnumDescriptor {
	return file_qclaogui_generativelanguage_v1_safety_proto_enumTypes[1].Descriptor()
}

func (SafetyRating_HarmProbability) Type() protoreflect.EnumType {
	return &file_qclaogui_generativelanguage_v1_safety_proto_enumTypes[1]
}

func (x SafetyRating_HarmProbability) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SafetyRating_HarmProbability.Descriptor instead.
func (SafetyRating_HarmProbability) EnumDescriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1_safety_proto_rawDescGZIP(), []int{0, 0}
}

// Block at and beyond a specified harm probability.
type SafetySetting_HarmBlockThreshold int32

const (
	// Threshold is unspecified.
	SafetySetting_HARM_BLOCK_THRESHOLD_UNSPECIFIED SafetySetting_HarmBlockThreshold = 0
	// Content with NEGLIGIBLE will be allowed.
	SafetySetting_BLOCK_LOW_AND_ABOVE SafetySetting_HarmBlockThreshold = 1
	// Content with NEGLIGIBLE and LOW will be allowed.
	SafetySetting_BLOCK_MEDIUM_AND_ABOVE SafetySetting_HarmBlockThreshold = 2
	// Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
	SafetySetting_BLOCK_ONLY_HIGH SafetySetting_HarmBlockThreshold = 3
	// All content will be allowed.
	SafetySetting_BLOCK_NONE SafetySetting_HarmBlockThreshold = 4
	// Turn off the safety filter.
	SafetySetting_OFF SafetySetting_HarmBlockThreshold = 5
)

// Enum value maps for SafetySetting_HarmBlockThreshold.
var (
	SafetySetting_HarmBlockThreshold_name = map[int32]string{
		0: "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
		1: "BLOCK_LOW_AND_ABOVE",
		2: "BLOCK_MEDIUM_AND_ABOVE",
		3: "BLOCK_ONLY_HIGH",
		4: "BLOCK_NONE",
		5: "OFF",
	}
	SafetySetting_HarmBlockThreshold_value = map[string]int32{
		"HARM_BLOCK_THRESHOLD_UNSPECIFIED": 0,
		"BLOCK_LOW_AND_ABOVE":              1,
		"BLOCK_MEDIUM_AND_ABOVE":           2,
		"BLOCK_ONLY_HIGH":                  3,
		"BLOCK_NONE":                       4,
		"OFF":                              5,
	}
)

func (x SafetySetting_HarmBlockThreshold) Enum() *SafetySetting_HarmBlockThreshold {
	p := new(SafetySetting_HarmBlockThreshold)
	*p = x
	return p
}

func (x SafetySetting_HarmBlockThreshold) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SafetySetting_HarmBlockThreshold) Descriptor() protoreflect.EnumDescriptor {
	return file_qclaogui_generativelanguage_v1_safety_proto_enumTypes[2].Descriptor()
}

func (SafetySetting_HarmBlockThreshold) Type() protoreflect.EnumType {
	return &file_qclaogui_generativelanguage_v1_safety_proto_enumTypes[2]
}

func (x SafetySetting_HarmBlockThreshold) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SafetySetting_HarmBlockThreshold.Descriptor instead.
func (SafetySetting_HarmBlockThreshold) EnumDescriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1_safety_proto_rawDescGZIP(), []int{1, 0}
}

// Safety rating for a piece of content.
//
// The safety rating contains the category of harm and the
// harm probability level in that category for a piece of content.
// Content is classified for safety across a number of
// harm categories and the probability of the harm classification is included
// here.
type SafetyRating struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The category for this rating.
	Category HarmCategory `protobuf:"varint,3,opt,name=category,proto3,enum=qclaogui.generativelanguage.v1.HarmCategory" json:"category,omitempty"`
	// Required. The probability of harm for this content.
	Probability SafetyRating_HarmProbability `protobuf:"varint,4,opt,name=probability,proto3,enum=qclaogui.generativelanguage.v1.SafetyRating_HarmProbability" json:"probability,omitempty"`
	// Was this content blocked because of this rating?
	Blocked       bool `protobuf:"varint,5,opt,name=blocked,proto3" json:"blocked,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SafetyRating) Reset() {
	*x = SafetyRating{}
	mi := &file_qclaogui_generativelanguage_v1_safety_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SafetyRating) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SafetyRating) ProtoMessage() {}

func (x *SafetyRating) ProtoReflect() protoreflect.Message {
	mi := &file_qclaogui_generativelanguage_v1_safety_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SafetyRating.ProtoReflect.Descriptor instead.
func (*SafetyRating) Descriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1_safety_proto_rawDescGZIP(), []int{0}
}

func (x *SafetyRating) GetCategory() HarmCategory {
	if x != nil {
		return x.Category
	}
	return HarmCategory_HARM_CATEGORY_UNSPECIFIED
}

func (x *SafetyRating) GetProbability() SafetyRating_HarmProbability {
	if x != nil {
		return x.Probability
	}
	return SafetyRating_HARM_PROBABILITY_UNSPECIFIED
}

func (x *SafetyRating) GetBlocked() bool {
	if x != nil {
		return x.Blocked
	}
	return false
}

// Safety setting, affecting the safety-blocking behavior.
//
// Passing a safety setting for a category changes the allowed probability that
// content is blocked.
type SafetySetting struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The category for this setting.
	Category HarmCategory `protobuf:"varint,3,opt,name=category,proto3,enum=qclaogui.generativelanguage.v1.HarmCategory" json:"category,omitempty"`
	// Required. Controls the probability threshold at which harm is blocked.
	Threshold     SafetySetting_HarmBlockThreshold `protobuf:"varint,4,opt,name=threshold,proto3,enum=qclaogui.generativelanguage.v1.SafetySetting_HarmBlockThreshold" json:"threshold,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SafetySetting) Reset() {
	*x = SafetySetting{}
	mi := &file_qclaogui_generativelanguage_v1_safety_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SafetySetting) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SafetySetting) ProtoMessage() {}

func (x *SafetySetting) ProtoReflect() protoreflect.Message {
	mi := &file_qclaogui_generativelanguage_v1_safety_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SafetySetting.ProtoReflect.Descriptor instead.
func (*SafetySetting) Descriptor() ([]byte, []int) {
	return file_qclaogui_generativelanguage_v1_safety_proto_rawDescGZIP(), []int{1}
}

func (x *SafetySetting) GetCategory() HarmCategory {
	if x != nil {
		return x.Category
	}
	return HarmCategory_HARM_CATEGORY_UNSPECIFIED
}

func (x *SafetySetting) GetThreshold() SafetySetting_HarmBlockThreshold {
	if x != nil {
		return x.Threshold
	}
	return SafetySetting_HARM_BLOCK_THRESHOLD_UNSPECIFIED
}

var File_qclaogui_generativelanguage_v1_safety_proto protoreflect.FileDescriptor

const file_qclaogui_generativelanguage_v1_safety_proto_rawDesc = "" +
	"\n" +
	"+qclaogui/generativelanguage/v1/safety.proto\x12\x1eqclaogui.generativelanguage.v1\x1a\x1fgoogle/api/field_behavior.proto\"\xc2\x02\n" +
	"\fSafetyRating\x12N\n" +
	"\bcategory\x18\x03 \x01(\x0e2,.qclaogui.generativelanguage.v1.HarmCategoryB\x04\xe2A\x01\x02R\bcategory\x12d\n" +
	"\vprobability\x18\x04 \x01(\x0e2<.qclaogui.generativelanguage.v1.SafetyRating.HarmProbabilityB\x04\xe2A\x01\x02R\vprobability\x12\x18\n" +
	"\ablocked\x18\x05 \x01(\bR\ablocked\"b\n" +
	"\x0fHarmProbability\x12 \n" +
	"\x1cHARM_PROBABILITY_UNSPECIFIED\x10\x00\x12\x0e\n" +
	"\n" +
	"NEGLIGIBLE\x10\x01\x12\a\n" +
	"\x03LOW\x10\x02\x12\n" +
	"\n" +
	"\x06MEDIUM\x10\x03\x12\b\n" +
	"\x04HIGH\x10\x04\"\xe5\x02\n" +
	"\rSafetySetting\x12N\n" +
	"\bcategory\x18\x03 \x01(\x0e2,.qclaogui.generativelanguage.v1.HarmCategoryB\x04\xe2A\x01\x02R\bcategory\x12d\n" +
	"\tthreshold\x18\x04 \x01(\x0e2@.qclaogui.generativelanguage.v1.SafetySetting.HarmBlockThresholdB\x04\xe2A\x01\x02R\tthreshold\"\x9d\x01\n" +
	"\x12HarmBlockThreshold\x12$\n" +
	" HARM_BLOCK_THRESHOLD_UNSPECIFIED\x10\x00\x12\x17\n" +
	"\x13BLOCK_LOW_AND_ABOVE\x10\x01\x12\x1a\n" +
	"\x16BLOCK_MEDIUM_AND_ABOVE\x10\x02\x12\x13\n" +
	"\x0fBLOCK_ONLY_HIGH\x10\x03\x12\x0e\n" +
	"\n" +
	"BLOCK_NONE\x10\x04\x12\a\n" +
	"\x03OFF\x10\x05*\xff\x02\n" +
	"\fHarmCategory\x12\x1d\n" +
	"\x19HARM_CATEGORY_UNSPECIFIED\x10\x00\x12\x1c\n" +
	"\x18HARM_CATEGORY_DEROGATORY\x10\x01\x12\x1a\n" +
	"\x16HARM_CATEGORY_TOXICITY\x10\x02\x12\x1a\n" +
	"\x16HARM_CATEGORY_VIOLENCE\x10\x03\x12\x18\n" +
	"\x14HARM_CATEGORY_SEXUAL\x10\x04\x12\x19\n" +
	"\x15HARM_CATEGORY_MEDICAL\x10\x05\x12\x1b\n" +
	"\x17HARM_CATEGORY_DANGEROUS\x10\x06\x12\x1c\n" +
	"\x18HARM_CATEGORY_HARASSMENT\x10\a\x12\x1d\n" +
	"\x19HARM_CATEGORY_HATE_SPEECH\x10\b\x12#\n" +
	"\x1fHARM_CATEGORY_SEXUALLY_EXPLICIT\x10\t\x12#\n" +
	"\x1fHARM_CATEGORY_DANGEROUS_CONTENT\x10\n" +
	"\x12!\n" +
	"\x1dHARM_CATEGORY_CIVIC_INTEGRITY\x10\vBQZOgithub.com/qclaogui/gaip/genproto/generativelanguage/apiv1/generativelanguagepbb\x06proto3"

var (
	file_qclaogui_generativelanguage_v1_safety_proto_rawDescOnce sync.Once
	file_qclaogui_generativelanguage_v1_safety_proto_rawDescData []byte
)

func file_qclaogui_generativelanguage_v1_safety_proto_rawDescGZIP() []byte {
	file_qclaogui_generativelanguage_v1_safety_proto_rawDescOnce.Do(func() {
		file_qclaogui_generativelanguage_v1_safety_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_qclaogui_generativelanguage_v1_safety_proto_rawDesc), len(file_qclaogui_generativelanguage_v1_safety_proto_rawDesc)))
	})
	return file_qclaogui_generativelanguage_v1_safety_proto_rawDescData
}

var (
	file_qclaogui_generativelanguage_v1_safety_proto_enumTypes = make([]protoimpl.EnumInfo, 3)
	file_qclaogui_generativelanguage_v1_safety_proto_msgTypes  = make([]protoimpl.MessageInfo, 2)
	file_qclaogui_generativelanguage_v1_safety_proto_goTypes   = []any{
		(HarmCategory)(0),                     // 0: qclaogui.generativelanguage.v1.HarmCategory
		(SafetyRating_HarmProbability)(0),     // 1: qclaogui.generativelanguage.v1.SafetyRating.HarmProbability
		(SafetySetting_HarmBlockThreshold)(0), // 2: qclaogui.generativelanguage.v1.SafetySetting.HarmBlockThreshold
		(*SafetyRating)(nil),                  // 3: qclaogui.generativelanguage.v1.SafetyRating
		(*SafetySetting)(nil),                 // 4: qclaogui.generativelanguage.v1.SafetySetting
	}
)

var file_qclaogui_generativelanguage_v1_safety_proto_depIdxs = []int32{
	0, // 0: qclaogui.generativelanguage.v1.SafetyRating.category:type_name -> qclaogui.generativelanguage.v1.HarmCategory
	1, // 1: qclaogui.generativelanguage.v1.SafetyRating.probability:type_name -> qclaogui.generativelanguage.v1.SafetyRating.HarmProbability
	0, // 2: qclaogui.generativelanguage.v1.SafetySetting.category:type_name -> qclaogui.generativelanguage.v1.HarmCategory
	2, // 3: qclaogui.generativelanguage.v1.SafetySetting.threshold:type_name -> qclaogui.generativelanguage.v1.SafetySetting.HarmBlockThreshold
	4, // [4:4] is the sub-list for method output_type
	4, // [4:4] is the sub-list for method input_type
	4, // [4:4] is the sub-list for extension type_name
	4, // [4:4] is the sub-list for extension extendee
	0, // [0:4] is the sub-list for field type_name
}

func init() { file_qclaogui_generativelanguage_v1_safety_proto_init() }
func file_qclaogui_generativelanguage_v1_safety_proto_init() {
	if File_qclaogui_generativelanguage_v1_safety_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_qclaogui_generativelanguage_v1_safety_proto_rawDesc), len(file_qclaogui_generativelanguage_v1_safety_proto_rawDesc)),
			NumEnums:      3,
			NumMessages:   2,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_qclaogui_generativelanguage_v1_safety_proto_goTypes,
		DependencyIndexes: file_qclaogui_generativelanguage_v1_safety_proto_depIdxs,
		EnumInfos:         file_qclaogui_generativelanguage_v1_safety_proto_enumTypes,
		MessageInfos:      file_qclaogui_generativelanguage_v1_safety_proto_msgTypes,
	}.Build()
	File_qclaogui_generativelanguage_v1_safety_proto = out.File
	file_qclaogui_generativelanguage_v1_safety_proto_goTypes = nil
	file_qclaogui_generativelanguage_v1_safety_proto_depIdxs = nil
}
